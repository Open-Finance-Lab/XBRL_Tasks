{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_checking(str, keywords=None):\n",
    "    \"\"\"\n",
    "    Check if a string satisfies the keyword rules:\n",
    "    1. Must contain all keywords in `and_keywords`.\n",
    "    2. Must contain at least one keyword in `or_keywords`.\n",
    "    3. Must not contain any keywords in `not_keywords`.\n",
    "\n",
    "    :param string: The input string to check.\n",
    "    :param and_keywords: List of keywords that must all be present in the string.\n",
    "    :param or_keywords: List of keywords where at least one must be present in the string.\n",
    "    :param not_keywords: List of keywords that must not be present in the string.\n",
    "    :return: True if the string satisfies the rules, False otherwise.\n",
    "    \"\"\"\n",
    "    and_keywords = keywords['and'] or []\n",
    "    or_keywords = keywords['or'] or []\n",
    "    not_keywords = keywords['not'] or []\n",
    "\n",
    "    string = str.lower()\n",
    "    if not all(keyword in string for keyword in and_keywords):\n",
    "        return False\n",
    "\n",
    "    if or_keywords and not any(keyword in string for keyword in or_keywords):\n",
    "        return False\n",
    "\n",
    "    if any(keyword in string for keyword in not_keywords):\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pre_xml(input_file, output_file, keywords=None):\n",
    "    \"\"\"\n",
    "    Process the input pre.xml file to extract and include specified sections:\n",
    "    1. Keep the first two lines.\n",
    "    2. Include <link:roleRef> with roleURI containing \"balance\" and \"sheet\", but not \"note\" or \"parenthetical\".\n",
    "    3. Include <link:presentationLink> corresponding to the extracted roleURI.\n",
    "    4. Keep the last line.\n",
    "\n",
    "    Return:\n",
    "    1. Matched roleURI.\n",
    "    2. List of unique xlink:label values from <link:loc> within <link:presentationLink>.\n",
    "\n",
    "    :param input_file: Path to the input pre.xml file.\n",
    "    :param output_file: Path to save the processed XML file.\n",
    "    :return: Tuple (matched_role_uris, unique_labels).\n",
    "    \"\"\"\n",
    "    tree = etree.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    namespaces = root.nsmap\n",
    "\n",
    "    # Find roleRef elements with the specified criteria\n",
    "    role_refs = root.findall('.//link:roleRef', namespaces)\n",
    "    matching_role_uris = []\n",
    "\n",
    "    for role_ref in role_refs:\n",
    "        role_uri = role_ref.get('roleURI')\n",
    "        if role_uri and keyword_checking(role_uri, keywords):\n",
    "            matching_role_uris.append(role_uri)\n",
    "            print(f\"    {role_uri}\")\n",
    "\n",
    "    if matching_role_uris==[]:\n",
    "        return [], []\n",
    "    \n",
    "    # Create a new root element for the output XML\n",
    "    new_root = etree.Element(root.tag, root.attrib, nsmap=root.nsmap)\n",
    "\n",
    "    # Add matching <link:roleRef> elements\n",
    "    for role_ref in role_refs:\n",
    "        role_uri = role_ref.get('roleURI')\n",
    "        if role_uri in matching_role_uris:\n",
    "            new_root.append(role_ref)\n",
    "\n",
    "    # Add corresponding <link:presentationLink> elements\n",
    "    presentation_links = root.findall('.//link:presentationLink', namespaces)\n",
    "    labels = list()\n",
    "    for presentation_link in presentation_links:\n",
    "        role = presentation_link.get('{http://www.w3.org/1999/xlink}role')\n",
    "        if role in matching_role_uris:\n",
    "            new_root.append(presentation_link)\n",
    "            # Extract xlink:label from <link:loc> elements\n",
    "            loc_elements = presentation_link.findall('link:loc', namespaces)\n",
    "            for loc in loc_elements:\n",
    "                href = loc.get('{http://www.w3.org/1999/xlink}href')\n",
    "                if href:\n",
    "                    label = href.rsplit('#', 1)[-1]\n",
    "                    labels.append(label)\n",
    "\n",
    "\n",
    "    new_tree = etree.ElementTree(new_root)\n",
    "    with open(output_file, 'wb') as f:\n",
    "        new_tree.write(f, xml_declaration=True, encoding='US-ASCII', pretty_print=True)\n",
    "\n",
    "    return matching_role_uris, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheets = {\n",
    "    \"and\": [\"balance\", \"sheet\"],\n",
    "    \"or\": [],\n",
    "    \"not\": [\"note\", \"parenthetical\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    http://www.bridgelinedigital.com/20230930/role/statement-consolidated-balance-sheets-\n"
     ]
    }
   ],
   "source": [
    "file_path = 'new_case_results/10k-blin-20230930/blin-20230930_pre.xml'\n",
    "output_path = 'new_case_results/10k-blin-20230930/blin-20230930_pre_filtered.xml'\n",
    "matching_role_uris, labels = filter_pre_xml(file_path, output_path, balance_sheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cal.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cal_xml(input_file, output_file, matching_role_uris):\n",
    "    \"\"\"\n",
    "    Process the input cal.xml file to extract and include specified sections:\n",
    "    1. Keep the first two lines.\n",
    "    2. Include <link:roleRef> with roleURI matching those obtained from pre.xml.\n",
    "    3. Include <link:calculationLink> corresponding to the matched roleURI.\n",
    "    4. Keep the last line.\n",
    "\n",
    "    :param input_file: Path to the input pre.xml file.\n",
    "    :param output_file: Path to save the processed XML file.\n",
    "    :param matching_role_uris: List of roleURI values obtained from pre.xml.\n",
    "    \"\"\"\n",
    "    tree = etree.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "    namespaces = root.nsmap\n",
    "\n",
    "    # Create a new root element for the output XML\n",
    "    new_root = etree.Element(root.tag, root.attrib, nsmap=root.nsmap)\n",
    "\n",
    "    # Add matching <link:roleRef> elements\n",
    "    role_refs = root.findall('.//link:roleRef', namespaces)\n",
    "    for role_ref in role_refs:\n",
    "        role_uri = role_ref.get('roleURI')\n",
    "        if role_uri in matching_role_uris:\n",
    "            new_root.append(role_ref)\n",
    "\n",
    "    # Add corresponding <link:calculationLink> elements\n",
    "    calculation_links = root.findall('.//link:calculationLink', namespaces)\n",
    "    for calculation_link in calculation_links:\n",
    "        role = calculation_link.get('{http://www.w3.org/1999/xlink}role')\n",
    "        if role in matching_role_uris:\n",
    "            new_root.append(calculation_link)\n",
    "\n",
    "    new_tree = etree.ElementTree(new_root)\n",
    "    with open(output_file, 'wb') as f:\n",
    "        new_tree.write(f, xml_declaration=True, encoding='US-ASCII', pretty_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './new_case_results/10k-blin-20230930/blin-20230930_cal.xml'\n",
    "output_path = './new_case_results/10k-blin-20230930/blin-20230930_cal_filtered.xml'\n",
    "filter_cal_xml(file_path, output_path, matching_role_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_def_xml(input_file, output_file, matching_role_uris):\n",
    "    \"\"\"\n",
    "    Process the input def.xml file to extract and include specified sections:\n",
    "    1. Keep the first two lines.\n",
    "    2. Keep all <link:arcroleRef> lines.\n",
    "    3. Include <link:roleRef> with roleURI matching those obtained from pre.xml.\n",
    "    4. Include <link:definitionLink> corresponding to the matched roleURI.\n",
    "    5. Keep the last line.\n",
    "\n",
    "    :param input_file: Path to the input pre.xml file.\n",
    "    :param output_file: Path to save the processed XML file.\n",
    "    :param matching_role_uris: List of roleURI values obtained from pre.xml.\n",
    "    \"\"\"\n",
    "    tree = etree.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "    namespaces = root.nsmap\n",
    "    new_root = etree.Element(root.tag, root.attrib, nsmap=root.nsmap)\n",
    "\n",
    "    # Add all <link:arcroleRef> elements\n",
    "    arcrole_refs = root.findall('.//link:arcroleRef', namespaces)\n",
    "    for arcrole_ref in arcrole_refs:\n",
    "        new_root.append(arcrole_ref)\n",
    "\n",
    "    # Add matching <link:roleRef> elements\n",
    "    role_refs = root.findall('.//link:roleRef', namespaces)\n",
    "    for role_ref in role_refs:\n",
    "        role_uri = role_ref.get('roleURI')\n",
    "        if role_uri in matching_role_uris:\n",
    "            new_root.append(role_ref)\n",
    "\n",
    "    # Add corresponding <link:definitionLink> elements\n",
    "    definition_links = root.findall('.//link:definitionLink', namespaces)\n",
    "    for definition_link in definition_links:\n",
    "        role = definition_link.get('{http://www.w3.org/1999/xlink}role')\n",
    "        if role in matching_role_uris:\n",
    "            new_root.append(definition_link)\n",
    "\n",
    "    new_tree = etree.ElementTree(new_root)\n",
    "    with open(output_file, 'wb') as f:\n",
    "        new_tree.write(f, xml_declaration=True, encoding='US-ASCII', pretty_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './new_case_results/10k-blin-20230930/blin-20230930_def.xml'\n",
    "output_path = './new_case_results/10k-blin-20230930/blin-20230930_def_filtered.xml'\n",
    "filter_def_xml(file_path, output_path, matching_role_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_xsd(input_file, output_file, role_uris):\n",
    "    \"\"\"\n",
    "    Process the input xsd file to extract and include specified sections:\n",
    "    1. Keep the first two lines.\n",
    "    2. Include all <xsd:import>, <xs:import>, <import> lines.\n",
    "    3. Include all lines within <xsd:annotation><xsd:appinfo>, <xs:annotation><xs:appinfo>, or <annotation><appinfo>, \n",
    "       including <link:linkbaseRef>.\n",
    "    4. Include <link:roleType> elements matching roleURI from pre.xml.\n",
    "    5. Include <xsd:element>, <xs:element>, <element> elements where id matches id from <link:roleType>.\n",
    "    6. Ensure <xsd:annotation>, <xs:annotation>, or <annotation> and their child <appinfo> sections are kept intact.\n",
    "    7. Keep the last line.\n",
    "\n",
    "    :param input_file: Path to the input xsd file.\n",
    "    :param output_file: Path to save the processed XML file.\n",
    "    :param role_uris: List of roleURI values obtained from pre.xml.\n",
    "    \"\"\"\n",
    "    # Parse the input XML file\n",
    "    tree = etree.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "    namespaces = root.nsmap\n",
    "\n",
    "    new_root = etree.Element(root.tag, root.attrib, nsmap=root.nsmap)\n",
    "\n",
    "    prefix_annotation = ''\n",
    "    if 'xsd' in namespaces:\n",
    "        prefix_annotation = 'xsd:'\n",
    "    elif 'xs' in namespaces:\n",
    "        prefix_annotation = 'xs:'\n",
    "\n",
    "    annotation_tag = f'{prefix_annotation}annotation'\n",
    "    appinfo_tag = f'{prefix_annotation}appinfo'\n",
    "    import_tag = f'{prefix_annotation}import'\n",
    "    element_tag = f'{prefix_annotation}element'\n",
    "\n",
    "    # Add all <xsd:import>, <xs:import>, <import> lines\n",
    "    # import_tags = ['xsd:import', 'import']\n",
    "    # for tag in import_tags:\n",
    "    imports = root.findall(f'.//{import_tag}', namespaces)\n",
    "    for imp in imports:\n",
    "        new_root.append(imp)\n",
    "\n",
    "    matching_ids = []\n",
    "\n",
    "    \n",
    "    # annotation_tags = ['xsd:annotation', 'annotation']\n",
    "    # for tag in annotation_tags:\n",
    "    annotations = root.findall(f'.//{annotation_tag}', namespaces)\n",
    "    for annotation in annotations:\n",
    "        # appinfo_tags = ['xsd:appinfo','appinfo']\n",
    "        # for appinfo_tag in appinfo_tags:\n",
    "        appinfo = annotation.find(f'.//{appinfo_tag}', namespaces)\n",
    "        if appinfo is not None:\n",
    "            filtered_appinfo = etree.Element(appinfo.tag, appinfo.attrib, nsmap=appinfo.nsmap)\n",
    "            # Add <link:roleType> elements matching roleURI from pre.xml\n",
    "            filtered_appinfo.tail = '\\n'\n",
    "            role_types = root.findall('.//link:roleType', namespaces)\n",
    "            for role_type in role_types:\n",
    "                role_uri = role_type.get('roleURI')\n",
    "                if role_uri in role_uris:\n",
    "                    filtered_appinfo.append(role_type)\n",
    "                    matching_ids.append(role_type.get('id'))\n",
    "                    \n",
    "            if len(filtered_appinfo):\n",
    "                filtered_annotation = etree.Element(annotation.tag, annotation.attrib, nsmap=annotation.nsmap)\n",
    "                filtered_annotation.append(filtered_appinfo)\n",
    "                new_root.append(filtered_annotation)\n",
    "\n",
    "\n",
    "    # Add <link:roleType> elements matching roleURI from pre.xml\n",
    "    # matching_ids = []\n",
    "    # role_types = root.findall('.//link:roleType', namespaces)\n",
    "    # for role_type in role_types:\n",
    "    #     role_uri = role_type.get('roleURI')\n",
    "    #     if role_uri in role_uris:\n",
    "    #         new_root.append(role_type)\n",
    "    #         matching_ids.append(role_type.get('id'))\n",
    "\n",
    "    # Add <xsd:element>, <xs:element>, <element> elements where id matches id from <link:roleType>\n",
    "    # element_tags = ['xsd:element','element']\n",
    "    # for tag in element_tags:\n",
    "    elements = root.findall(f'.//{element_tag}', namespaces)\n",
    "    for element in elements:\n",
    "        element_id = element.get('id')\n",
    "        if element_id in matching_ids:\n",
    "            new_root.append(element)\n",
    "\n",
    "    new_tree = etree.ElementTree(new_root)\n",
    "    with open(output_file, 'wb') as f:\n",
    "        new_tree.write(f, xml_declaration=True, encoding='UTF-8', pretty_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'new_case_results/10k-blin-20230930/blin-20230930.xsd'\n",
    "output_path = 'new_case_results/10k-blin-20230930/blin-20230930_filtered.xsd'\n",
    "uri = ['http://lake.com/role/CondensedConsolidatedBalanceSheets']\n",
    "filter_xsd(file_path, output_path, matching_role_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# htm.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_htm_xml(input_file, output_file, labels):\n",
    "    \"\"\"\n",
    "    Process the input htm.xml file to extract and include specified sections:\n",
    "    1. Keep the first three lines.\n",
    "    2. For each label in the labels list, substitute the first '-' with ':' and include matching lines.\n",
    "    3. Include <context> lines where id matches contextRef from the selected labels.\n",
    "    4. Include all <unit> lines.\n",
    "    5. Ensure the final order is: first lines, context, unit, labels, and the last line.\n",
    "    6. Keep the last line.\n",
    "    \n",
    "    :param input_file: Path to the input htm.xml file.\n",
    "    :param output_file: Path to save the processed XML file.\n",
    "    :param labels: List of labels from pre.xml with the first '-' replaced with ':'.\n",
    "    \"\"\"\n",
    "\n",
    "    tree = etree.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "    namespaces = root.nsmap\n",
    "\n",
    "    new_root = etree.Element(root.tag, root.attrib, nsmap=root.nsmap)\n",
    "    new_root.tail = '\\n'\n",
    "    schema_ref = root.find('.//link:schemaRef', namespaces)\n",
    "    if schema_ref is not None:\n",
    "        schema_ref.tail = '\\n\\t'\n",
    "        new_root.append(schema_ref)\n",
    "\n",
    "    # Step 2: Process labels and collect contextRefs\n",
    "    processed_facts = []\n",
    "    context_refs = []\n",
    "\n",
    "    for label in labels:\n",
    "        substituted_label = label.replace('_', ':', 1)\n",
    "        facts = root.findall(f'.//{substituted_label}', namespaces)\n",
    "        for fact in facts:\n",
    "            fact_str = etree.tostring(fact, encoding='unicode', pretty_print=True)\n",
    "            if fact_str not in processed_facts:\n",
    "                processed_facts.append(fact_str)\n",
    "                context_ref = fact.get('contextRef')\n",
    "                if context_ref:\n",
    "                    context_refs.append(context_ref)\n",
    "\n",
    "        # for label_element in label_elements:\n",
    "        #     fact = etree.tostring(label_element, encoding='unicode',pretty_print=True)\n",
    "        #     if label_str not in processed_labels:\n",
    "        #         processed_labels.add(label_str)\n",
    "        #         context_ref = label_element.get('contextRef')\n",
    "        #         if context_ref:\n",
    "        #             context_refs.add(context_ref)\n",
    "\n",
    "    # Step 3: Include <context> lines where id matches contextRef from step 2\n",
    "    included_contexts = []\n",
    "    context_labels = []\n",
    "    for context_id in context_refs:\n",
    "        context_elements = root.findall(f\".//context[@id='{context_id}']\", namespaces)\n",
    "\n",
    "        for context_element in context_elements:\n",
    "\n",
    "            for prefix in namespaces:\n",
    "                if prefix:\n",
    "                    # Search for any string matching \"{prefix}:...\"\n",
    "                    for element in context_element.iter():\n",
    "                        if element.tag.startswith(f\"{{{namespaces[prefix]}}}\"):\n",
    "                            dimension = element.get(\"dimension\")\n",
    "                            tag_text = element.text or \"\"\n",
    "                            if dimension:\n",
    "                                dimension = dimension.replace(':', '_', 1)\n",
    "                                context_labels.append(dimension)\n",
    "                            if tag_text:\n",
    "                                tag_text = tag_text.replace(':', '_', 1)\n",
    "                                context_labels.append(tag_text)\n",
    "\n",
    "            context_str = etree.tostring(context_element, encoding='unicode',pretty_print=True)\n",
    "            if context_str not in included_contexts:\n",
    "                included_contexts.append(context_str)\n",
    "\n",
    "    # Step 4: Include all <unit> lines\n",
    "    unit_elements = root.findall('.//unit', namespaces)\n",
    "    included_units = [etree.tostring(unit, encoding='unicode',pretty_print=True) for unit in unit_elements]\n",
    "\n",
    "    # Step 5: Add content to the new root in order\n",
    "    for context_str in included_contexts:\n",
    "        context_element = etree.fromstring(context_str)\n",
    "        context_element.tail = '\\n\\t'\n",
    "        new_root.append(context_element)\n",
    "    \n",
    "    for unit_str in included_units:\n",
    "        unit_element = etree.fromstring(unit_str)\n",
    "        unit_element.tail = '\\n\\t'\n",
    "        new_root.append(unit_element)\n",
    "\n",
    "    for label_str in processed_facts:\n",
    "        label_element = etree.fromstring(label_str)\n",
    "        label_element.tail = '\\n\\t'\n",
    "        new_root.append(label_element)\n",
    "\n",
    "    new_tree = etree.ElementTree(new_root)\n",
    "    with open(output_file, 'wb') as f:\n",
    "        new_tree.write(f, xml_declaration=True, encoding='utf-8', pretty_print=True)\n",
    "    \n",
    "    return context_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'new_case_results/10k-blin-20230930/blin20230930c_10k_htm.xml'\n",
    "output_path = 'new_case_results/10k-blin-20230930/blin20230930c_10k_htm_filtered.xml'\n",
    "context_labels = filter_htm_xml(file_path, output_path, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lab_xml(input_file, output_file, context_labels, pre_labels):\n",
    "    \"\"\"\n",
    "    Process the input lab.xml file to extract and include specified sections:\n",
    "    1. Keep the first two lines.\n",
    "    2. Keep all <link:roleRef> lines (should be 7 lines).\n",
    "    3. Include the <link:labelLink> section with filtered content:\n",
    "       - Use labels from context_labels and pre_labels.\n",
    "       - For each label:\n",
    "         1. Search <link:loc> where xlink:href matches the label.\n",
    "         2. Search <link:labelArc> where xlink:from matches the xlink:label obtained from <link:loc>.\n",
    "         3. Search <link:label> where xlink:label matches the xlink:to obtained from <link:labelArc>.\n",
    "       - Include these lines in order.\n",
    "    4. Keep the last lines </link:labelLink> and </link:linkbase>.\n",
    "\n",
    "    :param input_file: Path to the input lab.xml file.\n",
    "    :param output_file: Path to save the processed XML file.\n",
    "    :param context_labels: Labels obtained from htm.xml.\n",
    "    :param pre_labels: Labels obtained from pre.xml.\n",
    "    \"\"\"\n",
    "    tree = etree.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "    namespaces = root.nsmap\n",
    "\n",
    "    new_root = etree.Element(root.tag, root.attrib, nsmap=root.nsmap)\n",
    "    new_root.tail = '\\n'\n",
    "\n",
    "    # Step 2: Keep all <link:roleRef> lines\n",
    "    role_refs = root.findall('.//link:roleRef', namespaces)\n",
    "    for role_ref in role_refs:\n",
    "        new_root.append(role_ref)\n",
    "\n",
    "    # Step 3: Include <link:labelLink> section with filtered content\n",
    "    label_link = root.find('.//link:labelLink', namespaces)\n",
    "    if label_link is not None:\n",
    "        filtered_label_link = etree.Element(label_link.tag, label_link.attrib, nsmap=root.nsmap)\n",
    "        valid_labels = set(context_labels + pre_labels)\n",
    "\n",
    "        for label in valid_labels:\n",
    "            # Step 3.1: Find <link:loc> matching the label\n",
    "            loc_elements = label_link.findall('./link:loc', namespaces)\n",
    "            included_labels = set()\n",
    "\n",
    "            for loc in loc_elements:\n",
    "                href = loc.get('{http://www.w3.org/1999/xlink}href', '')\n",
    "                if '#' in href and href.split('#')[-1] == label:\n",
    "                    filtered_label_link.append(loc)\n",
    "                    included_labels.add(loc.get('{http://www.w3.org/1999/xlink}label'))\n",
    "\n",
    "            # Step 3.2: Find <link:labelArc> matching xlink:from from <link:loc>\n",
    "            label_arcs = label_link.findall('./link:labelArc', namespaces)\n",
    "            included_tos = set()\n",
    "\n",
    "            for label_arc in label_arcs:\n",
    "                label_from = label_arc.get('{http://www.w3.org/1999/xlink}from')\n",
    "                if label_from in included_labels:\n",
    "                    filtered_label_link.append(label_arc)\n",
    "                    included_tos.add(label_arc.get('{http://www.w3.org/1999/xlink}to'))\n",
    "\n",
    "            # Step 3.3: Find <link:label> matching xlink:to from <link:labelArc>\n",
    "            label_elements = label_link.findall('./link:label', namespaces)\n",
    "            for label_element in label_elements:\n",
    "                label_attr = label_element.get('{http://www.w3.org/1999/xlink}label')\n",
    "                if label_attr in included_tos:\n",
    "                    filtered_label_link.append(label_element)\n",
    "        filtered_label_link.tail = '\\n'\n",
    "        new_root.append(filtered_label_link)\n",
    "\n",
    "    new_tree = etree.ElementTree(new_root)\n",
    "    with open(output_file, 'wb') as f:\n",
    "        new_tree.write(f, xml_declaration=True, encoding='utf-8', pretty_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './new_case_results/10k-blin-20230930/blin-20230930_lab.xml'\n",
    "output_path = './new_case_results/10k-blin-20230930/blin-20230930_lab_filtered.xml'\n",
    "filter_lab_xml(file_path, output_path, context_labels, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = {\n",
    "    \"balance_sheets\": {\n",
    "        \"and\": [\"balance\", \"sheet\"],\n",
    "        \"or\": [],\n",
    "        \"not\": [\"note\", \"parenthetical\"]\n",
    "    },\n",
    "    \"balance_sheets_parenthetical\": {\n",
    "        \"and\": [\"balance\", \"sheet\", \"parenthetical\"],\n",
    "        \"or\": [],\n",
    "        \"not\": [\"note\"]\n",
    "    },\n",
    "    \"income_statements\": {\n",
    "        \"and\": [\"statement\"],\n",
    "        \"or\": [\"operation\",\"income\",\"incomeloss\"],\n",
    "        \"not\": [\"note\", \"comprehensive\"]\n",
    "    },\n",
    "    \"comprehensive_income_statements\": {\n",
    "        \"and\": [\"comprehensive\", \"statement\"],\n",
    "        \"or\": [\"operation\",\"income\",\"incomeloss\"],\n",
    "        \"not\": [\"note\"]\n",
    "    },\n",
    "    \"statements_of_cash_flows\": {\n",
    "        \"and\": [\"statement\", \"cash\", \"flow\"],\n",
    "        \"or\": [],\n",
    "        \"not\": [\"note\"]\n",
    "    },\n",
    "    \"statements_of_equity\": {\n",
    "        \"and\": [\"statement\"],\n",
    "        \"or\": [\"equity\", \"change\",\"stockholder\"],\n",
    "        \"not\": [\"note\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_folder(folder_path, results_folder):\n",
    "\n",
    "    for subfolder_name in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            subfolder_results_path = os.path.join(results_folder, subfolder_name)\n",
    "            os.makedirs(subfolder_results_path, exist_ok=True)\n",
    "            print(subfolder_name)\n",
    "            for statement_name in KEYWORDS.keys():\n",
    "                statement_path = os.path.join(subfolder_results_path, statement_name)\n",
    "                os.makedirs(statement_path, exist_ok=True)\n",
    "                for file_name in os.listdir(subfolder_path):\n",
    "                    file_path = os.path.join(subfolder_path, file_name)\n",
    "\n",
    "                    if file_name.endswith(\"pre.xml\"):\n",
    "                        output_path = os.path.join(statement_path, file_name)\n",
    "                        # print(f\"   {file_path}\")\n",
    "                        # print(f\"   {output_path}\")\n",
    "                        print(f\"   {statement_name}\")\n",
    "                        matching_role_uris, pre_labels = filter_pre_xml(file_path, output_path, KEYWORDS[statement_name])\n",
    "                        print()\n",
    "                        context_labels = []\n",
    "\n",
    "                        if matching_role_uris == []:\n",
    "                            continue\n",
    "\n",
    "                        calc_file_path = file_path.replace(\"pre.xml\", \"cal.xml\")\n",
    "                        calc_output_path = output_path.replace(\"pre.xml\", \"cal.xml\")\n",
    "                        def_file_path = file_path.replace(\"pre.xml\", \"def.xml\")\n",
    "                        def_output_path = output_path.replace(\"pre.xml\", \"def.xml\")\n",
    "                        xsd_file_path = file_path.replace(\"_pre.xml\", \".xsd\")\n",
    "                        xsd_output_path = output_path.replace(\"_pre.xml\", \".xsd\")\n",
    "                        lab_file_path = file_path.replace(\"pre.xml\", \"lab.xml\")\n",
    "                        lab_output_path = output_path.replace(\"pre.xml\", \"lab.xml\")\n",
    "\n",
    "                        filter_cal_xml(calc_file_path, calc_output_path, matching_role_uris)\n",
    "                        filter_def_xml(def_file_path, def_output_path, matching_role_uris)\n",
    "                        filter_xsd(xsd_file_path, xsd_output_path, matching_role_uris)\n",
    "\n",
    "                        for f_name in os.listdir(subfolder_path):\n",
    "                            f_path= os.path.join(subfolder_path, f_name)\n",
    "                            if f_name.endswith(\"htm.xml\"):\n",
    "                                htm_output_path = os.path.join(statement_path, f_name)\n",
    "                                context_labels = filter_htm_xml(f_path, htm_output_path, pre_labels)\n",
    "                                break\n",
    "                        \n",
    "                        filter_lab_xml(lab_file_path, lab_output_path, context_labels, pre_labels)\n",
    "                        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10q-lake-20241031\n",
      "   balance_sheets\n",
      "    http://lake.com/role/CondensedConsolidatedBalanceSheets\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "    http://lake.com/role/CondensedConsolidatedBalanceSheetsParenthetical\n",
      "\n",
      "   income_statements\n",
      "    http://lake.com/role/CondensedConsolidatedStatementsOfOperationsUnaudited\n",
      "\n",
      "   comprehensive_income_statements\n",
      "    http://lake.com/role/CondensedConsolidatedStatementsOfComprehensiveIncomeLossUnaudited\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://lake.com/role/CondensedConsolidatedStatementsOfCashFlowsUnaudited\n",
      "\n",
      "   statements_of_equity\n",
      "    http://lake.com/role/CondensedConsolidatedStatementsOfStockholdersEquityUnaudited\n",
      "\n",
      "10q-star-20241031\n",
      "   balance_sheets\n",
      "    http://star.com/role/CondensedConsolidatedBalanceSheets\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "    http://star.com/role/CondensedConsolidatedBalanceSheetsParenthetical\n",
      "\n",
      "   income_statements\n",
      "    http://star.com/role/CondensedConsolidatedStatementsOfOperationsUnaudited\n",
      "\n",
      "   comprehensive_income_statements\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://star.com/role/CondensedConsolidatedStatementsOfCashFlowsUnaudited\n",
      "\n",
      "   statements_of_equity\n",
      "    http://star.com/role/CondensedConsolidatedStatementsOfChangesInStockholdersDeficitUnaudited\n",
      "\n",
      "10q-odc-20241031\n",
      "   balance_sheets\n",
      "    http://www.oildri.com/role/CondensedConsolidatedBalanceSheets\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "    http://www.oildri.com/role/CondensedConsolidatedBalanceSheetParenthetical\n",
      "\n",
      "   income_statements\n",
      "    http://www.oildri.com/role/CondensedConsolidatedStatementsofIncome\n",
      "\n",
      "   comprehensive_income_statements\n",
      "    http://www.oildri.com/role/CondensedConsolidatedStatementsofComprehensiveIncome\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://www.oildri.com/role/CondensedConsolidatedStatementsofCashFlows\n",
      "\n",
      "   statements_of_equity\n",
      "    http://www.oildri.com/role/ConsolidatedStatementsofStockholdersEquityStatement\n",
      "\n",
      "10q-boxxy-20241031\n",
      "   balance_sheets\n",
      "    http://boxxy.com/role/BalanceSheets\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "    http://boxxy.com/role/BalanceSheetsParenthetical\n",
      "\n",
      "   income_statements\n",
      "    http://boxxy.com/role/StatementsOfOperationsUnaudited\n",
      "\n",
      "   comprehensive_income_statements\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://boxxy.com/role/StatementsOfCashFlowsUnaudited\n",
      "\n",
      "   statements_of_equity\n",
      "    http://boxxy.com/role/StatementsOfStockholdersDeficitUnaudited\n",
      "\n",
      "10q-alzm-20241031\n",
      "   balance_sheets\n",
      "    http://alzamend.com/role/BalanceSheets\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "    http://alzamend.com/role/BalanceSheetsParenthetical\n",
      "\n",
      "   income_statements\n",
      "    http://alzamend.com/role/StatementsOfOperations\n",
      "\n",
      "   comprehensive_income_statements\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://alzamend.com/role/StatementsOfCashFlows\n",
      "\n",
      "   statements_of_equity\n",
      "    http://alzamend.com/role/StatementsOfStockholdersDeficitEquity\n",
      "\n",
      "10q-bned-20241026\n",
      "   balance_sheets\n",
      "    http://www.bned.com/role/ConsolidatedBalanceSheets\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "\n",
      "   income_statements\n",
      "\n",
      "   comprehensive_income_statements\n",
      "    http://www.bned.com/role/ConsolidatedStatementsofOperationsandComprehensiveLoss\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://www.bned.com/role/StatementofCashFlowsStatement\n",
      "\n",
      "   statements_of_equity\n",
      "    http://www.bned.com/role/ConsolidatedStatementofEquityStatement\n",
      "\n",
      "10k-blin-20230930\n",
      "   balance_sheets\n",
      "    http://www.bridgelinedigital.com/20230930/role/statement-consolidated-balance-sheets-\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "    http://www.bridgelinedigital.com/20230930/role/statement-consolidated-balance-sheets-parentheticals\n",
      "\n",
      "   income_statements\n",
      "    http://www.bridgelinedigital.com/20230930/role/statement-consolidated-statements-of-operations-\n",
      "\n",
      "   comprehensive_income_statements\n",
      "    http://www.bridgelinedigital.com/20230930/role/statement-consolidated-statements-of-comprehensive-incomeloss-\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://www.bridgelinedigital.com/20230930/role/statement-consolidated-statements-of-cash-flows\n",
      "\n",
      "   statements_of_equity\n",
      "    http://www.bridgelinedigital.com/20230930/role/statement-consolidated-statements-of-stockholders-equity\n",
      "\n",
      "10q-spwh-20241102\n",
      "10q-pcnt-20240131\n",
      "   balance_sheets\n",
      "    http://pointofcarenano.com/role/CondensedBalanceSheets\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "    http://pointofcarenano.com/role/CondensedBalanceSheetsParenthetical\n",
      "\n",
      "   income_statements\n",
      "    http://pointofcarenano.com/role/CondensedStatementsOfOperations\n",
      "\n",
      "   comprehensive_income_statements\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://pointofcarenano.com/role/CondensedStatementsOfCashFlows\n",
      "\n",
      "   statements_of_equity\n",
      "\n",
      "10k-none-20240831\n",
      "   balance_sheets\n",
      "    http://e-smart.io/role/BalanceSheets\n",
      "\n",
      "   balance_sheets_parenthetical\n",
      "    http://e-smart.io/role/BalanceSheetsParenthetical\n",
      "\n",
      "   income_statements\n",
      "    http://e-smart.io/role/StatementsOfOperations\n",
      "\n",
      "   comprehensive_income_statements\n",
      "\n",
      "   statements_of_cash_flows\n",
      "    http://e-smart.io/role/StatementsOfCashFlows\n",
      "\n",
      "   statements_of_equity\n",
      "    http://e-smart.io/role/StatementsOfStockholdersEquity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_process_folder(\"new_case_results\", \"new_case_results_segmentation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
